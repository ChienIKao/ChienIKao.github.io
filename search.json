[{"title":"國網中心跳板機連線教學","url":"/%E4%BD%BF%E7%94%A8%E8%B7%B3%E6%9D%BF%E6%A9%9F%E9%80%A3%E7%B7%9A%E5%88%B0%E5%85%A7%E9%83%A8%20VM/","content":"\n  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\n  \n    \n      \n      \n        當前文章暫不對外可見，請輸入密碼後查看！\n      \n      \n        \n        \n      \n    \n  \n\n","categories":["NCHC"],"tags":["private"]},{"title":"AutoGPT 介紹","url":"/AutoGPT/","content":"# License\n\n大部分模組採 MIT 開源​\n另有部分平台 ( autogpt_platform/ ) 使用 Polyform Shield 授權（對商業部署有一定限制）​\n純開源部分可自由商用，但完整平台需留意授權區分。\n\n# 架構與功能特色\n\n採用自主迭代 Agent 架構：給定高階目標後，Agent 會將其拆解為子任務，反覆執行「思考 - 行動 - 觀察」循環，直到達成目標​ [1]。\n能自動進行網路搜尋、調用 API 等工具來完成任務，無需人工介入​。\n預設使用 GPT-3.5/GPT-4 作為模型後端，具備一定的內部記憶和上下文累積能力來支撐連續行動。\n提供 Plugin 插件機制擴充功能，可加入瀏覽器、檔案讀寫等各類工具模組使用。\n\n# 擴充性與客製化\n\n最初框架較單一（一個 Agent 循環決策），但透過插件可以增添功能模塊。\n官方插件庫預置了許多常用插件，社群也貢獻了大量擴充功能​ [2]。\n最新推出的 AutoGPT Forge 工具包允許開發者重用其元件，快速組裝屬於自己的 Agent 應用​。\n因此現在除了調整提示語之外，也能在框架內進行較深入的客製化（自定義工作流程、加入新行為模組等），擴充性相對完善。\n\n# 使用者學習曲線與文件\n\n初期使用者常反映其自主回圈行為難以預料，需要調整提示避免無效循環，存在學習成本。\n不過隨著社群積累了大量經驗，攻略和最佳實踐已相當豐富。\n官方文件（docs.agpt.co）涵蓋從基礎安裝到進階開發，並新增了圖形界面和現成 Agent 模板降低使用難度。\n因此技術使用者能較快上手框架，但一般非程式背景者直接使用仍有一定門檻。\n\n# 作為 SDK/API 封裝供整合（Function Calling、MCP 支援）\n\n最新的 AutoGPT 平臺將核心 Agent 運行從 UI 分離，提供了後端 Server 來管理 Agent 生命週期​。\n理論上可透過 API 或觸發器調用該 Server 上的 Agent 任務（例如由前端發送任務請求）。\n而傳統 AutoGPT 可以通過函式封裝其 loop，在每步決策時與前端交互，但實現較為複雜。\n對 Function Calling 已有支援（利用 GPT-4 模型內建的函數調用特性或透過插件實現工具調用）。\n對 MCP 等新協議暫無原生支援，但隨著多 Agent 標準發展，預期會逐步兼容。總的來說，如今的 AutoGPT 更趨向平臺化，可考慮作為後端服務供其他系統使用，但整合時需注意其運行效率和狀態管理。\n\n# 優缺點總結\n# 優點\n\n真正開創了自主 AI 代理的風潮，單 Agent 即可自我循環完成複雜任務​。\n使用上相對簡單，給定目標後能自動執行一系列行動，不需要精細的流程設計。\n擁有海量社群支持，插件生態豐富，各種擴充功能（網路、郵件、資料庫等）易於取得​。\n近期發展出圖形介面和定制工具包，使其不再僅限於命令列使用。\n\n# 缺點\n\n自主性過強有時反而是劣勢：早期版本常出現無效循環或不可靠的決策，需要人工監督或提示調整。\n雖然有長程記憶，但記憶體容易隨著循環變長而稀釋，導致上下文遺失。\n過去作為獨立應用難以與其他系統交互，不過這點隨平臺化在改善中。\n另有部分代碼採用非 MIT 授權，商業使用需注意。\n\n# 參考資料\n\n\n\nen.wikipedia.org ↩︎\n\nAutoGPT Plugins ↩︎\n\n\n\n","categories":["NCHC","Agent"],"tags":["NCHC","Agent"]},{"title":"AI Agent 框架比較","url":"/AI%E4%BB%A3%E7%90%86%E6%A1%86%E6%9E%B6%E9%80%B2%E9%9A%8E%E6%AF%94%E8%BC%83%E5%88%86%E6%9E%90/","content":"# LangGraph\n# 實際應用案例\n\nLangGraph 由 LangChain 團隊推出，用於構建複雜多角色 LLM 代理系統，已被多家企業採用。\n\n例如，Replit 利用 LangGraph 開發線上程式助理，強調代理執行可靠性，以便支援數百萬使用者 (LangGraph)。\nUber、LinkedIn、GitLab 等公司也使用 LangGraph 打造可控的 AI 工作流程 (GitHub - langchain-ai/langgraph: Build resilient language agents as graphs.)。\n在產業案例方面，挪威郵輪 Norwegian Cruise Line 採用 LangGraph 建立遊客服務的生成式 AI 解決方案，提升客戶體驗 (What is LangGraph? | IBM)。\nLangGraph 也可用於模擬真人對話助理（如類似 Google Duplex 的對話服務）以及機器人控制、自動駕駛等多智能體系統 (What is LangGraph? | IBM) (What is LangGraph? | IBM)。\n\n\n\n# 模型支援與兼容性\n\nLangGraph 基於 LangChain，因此兼容多種 LLM。\n\n預設支援 OpenAI GPT-3.5、GPT-4 系列模型，並已擴充支援 Anthropic Claude 以及 Azure OpenAI 等模型接口 (What is LangGraph? | IBM)。\n\n\n開源社群也為 LangGraph 增加了對其他模型的支援，透過 LLM API 設定可以切換不同模型 (What is LangGraph? | IBM)。\n\n例如，可整合本地 LLM 推理服務（如 LLaMA-FastChat、Ollama）來使用 Meta 的 LLaMA 模型 (What is LangGraph? | IBM)。\n\n\nLangGraph 與 LangChain 元件整合，使更換模型供應商相當簡單 —— 例如一行程式即可改用 Google Gemini 模型（透過  ChatGoogleGenerativeAI  介面） (How to Implement a GenAI Agent using Autogen or LangGraph | by Lak Lakshmanan | TDS Archive | Medium)。\n此外，LangGraph 支援 OpenAI 函數調用功能與工具使用\n\n開發者可在節點中定義工具函式，代理會依照對話狀態選擇適當函式執行。\n\n\nLangGraph 也能結合 Anthropic 的 Model Context Protocol (MCP) 標準，以統一的方式連接外部資料源和工具，提升代理與外部環境交互的能力 (GitHub - esxr/langgraph-mcp: LangGraph solution template for MCP) (GitHub - esxr/langgraph-mcp: LangGraph solution template for MCP)。\n\n# 部署複雜度與資源需求\n\nLangGraph 以 Python 套件形式提供（ pip install langgraph ），可輕鬆整合到現有應用中 (GitHub - langchain-ai/langgraph: Build resilient language agents as graphs.)。\n由於其構建在 LangChain 之上，開發者熟悉 LangChain 即可快速上手。\nLangGraph 強調可控性與可靠性，提供長期記憶體與人工介入機制來管理長任務流程 (GitHub - langchain-ai/langgraph: Build resilient language agents as graphs.)。\n在部署方面，LangGraph 無特殊硬體需求：\n\n若使用雲端 LLM API（OpenAI/Anthropic 等），主要負擔在遠端服務；\n若需要執行本地開源模型，則需架設相應的推理服務（可能需要 GPU 以運行大型模型）。\n官方並提供 LangGraph Studio 桌面應用作為可視化介面，用戶可透過圖形化拖拽設計代理工作流 (What is LangGraph? | IBM)。\n因此在本地開發測試相對容易，而要大規模部署於生產環境，可將 LangGraph 服務容器化 (Docker) 並結合企業基礎設施。\n\n\n總體而言，LangGraph 本身輕量，資源消耗取決於所調用的 LLM 大小和數量。\n\n# AutoGen\n# 實際應用案例\n\nAutoGen（由微軟研究院開源）是一款多代理對話協作框架，強調讓多個 LLM 代理彼此對話來完成任務 (AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation - Microsoft Research)。\n研究人員已用 AutoGen 構建多種試驗應用，涵蓋數學解題、程式編寫、問答系統、供應鏈優化、線上決策以及娛樂遊戲等領域 (AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation - Microsoft Research)。\n具體案例包括：\n\n讓一個「寫程式代理」與一個「除錯代理」合作完成代碼任務 (Microsoft's AutoGen. A guide to code-executing agents | by Tereza Tizkova | E2B — Cloud runtime for AI agents | Medium)—— 一個代理根據使用者需求產生程式碼，另一代理審視並修正錯誤，必要時再交由下一步的代理（如執行結果可視化）處理 (Microsoft's AutoGen. A guide to code-executing agents | by Tereza Tizkova | E2B — Cloud runtime for AI agents | Medium)。\n\n\n這種專家代理分工模式已被用於資料分析等場景，例如結合語音識別與翻譯：\n\n一個代理使用 OpenAI Whisper 轉錄音檔文字，另一代理再將文字翻譯成目標語言 (Multi-Agent AutoGen with Functions - Step-by-Step with Code Examples | by Dr. Ernesto Lee | Medium)。\n\n\nAutoGen 自 2023 年推出以來在開源社群引起廣泛關注，Google Trends 顯示其熱度在多代理框架中名列前茅 (Microsoft's AutoGen. A guide to code-executing agents | by Tereza Tizkova | E2B — Cloud runtime for AI agents | Medium)。\n\n# 模型支援與兼容性\n\nAutoGen 設計為模型無關的代理架構，支援多種大型模型。\n初期主要支持 OpenAI ChatGPT (GPT-3.5、GPT-4) 作為對話引擎 (AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation - Microsoft Research)；\n隨後版本陸續擴增對 Anthropic Claude 的支援（v0.2.30 起提供 Anthropic API 客戶端） (Anthropic Claude | AutoGen 0.2 - Microsoft Open Source)。\nAutoGen 0.4 開始強化非 OpenAI 模型整合，新增對 Google Gemini、Mistral AI、Together AI、Groq 等平台的客戶端，可使用超過 75 種不同的模型 (Enhanced Support for Non-OpenAI Models | AutoGen 0.2) (Enhanced Support for Non-OpenAI Models | AutoGen 0.2)。\n例如，安裝相應擴展後，可直接在配置中指定  api_type  和模型名稱來調用 Amazon Bedrock 上的 Anthropic 或 Cohere 模型 (Enhanced Support for Non-OpenAI Models | AutoGen 0.2) (Enhanced Support for Non-OpenAI Models | AutoGen 0.2)。\n此外 AutoGen 具備工具調用與結構化輸出能力：\n\n代理可透過內建的函式執行模組調用外部工具（如執行程式碼、網路搜尋），或要求 LLM 產生特定格式輸出以便解析 (Multi-Agent AutoGen with Functions - Step-by-Step with Code Examples | by Dr. Ernesto Lee | Medium)。\n隨著 Anthropic 推出 MCP 協定，AutoGen 也能輕鬆介接；\n實踐證明只需幾行程式碼即可讓 AutoGen 代理使用 MCP 工具，統一調用例如資料庫查詢、郵件服務等功能 (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model)) (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model))。\n這使 AutoGen 在模型和工具支援上非常靈活。\n\n\n\n# 部署的複雜度與資源需求\n\nAutoGen 以 Python 套件形式提供（曾用名  pyautogen ，現已更名為 AG2），安裝相對簡單：\n\n例如  pip install autogen  或  pip install ag2[openai]  (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n其架構採用非同步、事件驅動設計，允許代理並行對話和長時執行，適合部署在分散式系統中 (AutoGen - Microsoft Research) (AutoGen - Microsoft Research)。\nAutoGen 支持 Python 和 .NET 平台的代理互通，方便融入不同技術棧 (AutoGen - Microsoft Research)。\n在本地開發時，可使用 Jupyter Notebook 等進行原型實驗，官方也提供了大量範例程式和筆記來說明各種使用情境 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n資源需求方面，AutoGen 框架本身輕量，但典型應用會使用 GPT-4 這類大型模型，其上下文調用需要穩定的網路和 API 授權。\n如果以雲端 API 為主，運行 AutoGen 代理對 CPU/GPU 無特殊要求；但若使用本地模型（例如通過 Hugging Face 或本地推理引擎），則需對應的硬體（高階 GPU 或充裕記憶體）來承載推理。\n在工具執行方面，AutoGen 已內建沙盒執行環境，例如自動將代理產生的代碼在隔離的 Docker 容器中運行，確保安全 (Enhanced Support for Non-OpenAI Models | AutoGen 0.2)。\n因此，部署 AutoGen 時最好具備容器化基礎設施來管理這些子任務。總的來說，AutoGen 的上手成本適中，得益於微軟的開源投入和完善文檔，其社群支援活躍；開發者更需關注的是後端模型運算資源及代理調優，而非框架本身的負擔。\n\n\n\n# AG2\n# 實際應用案例\n\nAG2 是 AutoGen 的進化開源版本（被稱為「AgentOS」），由社群志願者維護並持續擴展 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\nAG2 強調生產級的多代理流程編排能力，已在企業中獲得應用。\n例如資料工程平台 Nexla 使用 AG2 打造名為 “NOVA” 的資料工程助手 (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2)。\n透過 NOVA，使用者只需以自然語言描述資料轉換需求，AG2 代理即會將複雜資料管道自動拆解為可執行步驟並完成配置 (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2) (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2)。\nNexla CEO 表示 AG2 的人類介入機制和可靠性使得 NOVA 能在保障治理和準確性的同時，提供直觀高效的用戶體驗 (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2)。\n除了企業案例，AG2 官方還提供客服助理、遊戲設計、旅遊規劃等示範場景的工作流程範本，展示其在不同領域處理複雜任務的能力 (Key Features - AG2)。\n\n# 模型支援與兼容性\n\nAG2 繼承了 AutoGen 的廣泛模型支援，能夠使用市面上主流的閉源和開源 LLM。\n它內建對 OpenAI GPT-4/GPT-3.5 的支持，並直接整合 Anthropic Claude、Google Gemini 等模型客戶端，以及多種開源模型。\nAutoGen 時期實現的擴充在 AG2 中持續有效 —— 開發者可以輕鬆改用 Anthropic、Mistral、Llama2 等超過 75 種模型作為代理智慧引擎，只需安裝對應擴展並調整配置 (Enhanced Support for Non-OpenAI Models | AutoGen 0.2)。\nAG2 也支持自定義模型客戶端：\n\n例如可透過 Together.AI 或 HuggingFace 接口接入本地微調模型。\n\n\n功能上，AG2 支持結構化提示輸出、檢索增強生成 (RAG)、代碼執行等進階能力 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n代理之間的對話模式亦可定制，包括多代理群聊、巢狀對話、自主 / 人工混合等 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n在工具使用方面，AG2 延續 AutoGen 的做法，允許註冊自定義工具函式供代理調用，並可將人類作為一種特殊代理插入回路中 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n此外，AG2 與最新的 MCP 協定兼容良好 —— 開發者已示範只用兩行代碼就讓 AG2 代理接入 Anthropic MCP 工具伺服，實現與外部資料源的雙向連接 (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model)) (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model))。\n這使 AG2 能緊跟業界標準，靈活協作多模型、多工具完成任務。\n\n# 實際部署的複雜度與資源需求\n\n作為完全開源的框架，AG2 的部署靈活度很高。開發者可依需求將其作為後端程式庫嵌入應用，或獨立部署為服務。\n安裝方面只需 Python 3.9+ 環境和相應套件：\n\n例如  pip install ag2[openai]  將安裝核心及 OpenAI 支持 (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)。\n\n\nAG2 的架構經過重新設計以強調可擴充性與穩定性：\n\n內部採用事件隊列管理代理訊息，支援大規模併發和任務分散處理 (AutoGen - Microsoft Research) (AutoGen - Microsoft Research)。\n其內建監控和除錯工具（整合 OpenTelemetry），方便在生產環境追蹤代理行為 (AutoGen - Microsoft Research)。\n\n\n在部署複雜度上，相較 AutoGen，AG2 更加模組化，官方文件提供了快速入門範例和常見用例模板，降低開發者構建自定義代理系統的門檻 (Key Features - AG2) (Key Features - AG2)。\n資源需求方面，AG2 本身不執行大型模型推理，因此運行框架只需一般的伺服器（CPU 即可）。\n實際資源消耗取決於所用 LLM 和工具：\n\n例如使用 GPT-4 API 則主要消耗雲端計算點數；\n\n\n如需本地部署開源模型，則須考慮相應的 GPU 記憶體和運算力。\n在高並發場景下，適當擴容代理服務執行節點（比如用容器集群）可以提高吞吐量。\n總而言之，AG2 提供了接近生產級的一站式代理開發解決方案，易於本地部署且擴展彈性高，企業可依自身資源從單機原型順利過渡到分布式生產環境。\n\n# MetaGPT\n# 實際應用案例\n\nMetaGPT 是由 DeepWisdom 公司開源的多代理協同框架，其特色是在軟體研發場景中扮演一整個 AI 軟體團隊 (What is MetaGPT ? | IBM )。\nMetaGPT 將 GPT-4/GPT-3.5 等模型代理分配為不同專業角色（如產品經理、架構師、項目經理、工程師），並讓它們按照軟體開發的標準流程和 SOP 進行協作 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium) (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n只需輸入一句產品點子，它就能自動產出詳細的需求文檔、用戶故事、競品分析、資料結構設計、API 設計甚至代碼實現 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n\n例如，開發者輸入「製作一款類似 Flappy Bird 的簡單遊戲」，MetaGPT 會讓「產品經理代理」先生成需求和用戶故事，「架構師代理」設計系統結構，「工程師代理」編寫代碼，「測試代理」審查改進，最終輸出完整的項目說明與代碼存檔 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n這種架構在 2023 年引發關注，GitHub 上迅速累積了大量星標，展示了多代理分工協作進行元編程的潛力 (What is MetaGPT ? | IBM )。\n不過，MetaGPT 目前多用於研究和原型試驗，例如自動產生樣板專案、技術文檔等；真正大規模商業落地的案例相對較少，更多是作為概念驗證工具被討論。\n\n\n\n# 模型支援與兼容性\n\nMetaGPT 的代理主要基於 OpenAI 的 GPT 系列模型運作。\n開箱即用時，它假定有 GPT-4 作為核心智能引擎，以確保各角色代理具備足夠的推理和生成能力 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n在框架剛推出時，對其他模型的支持有限。不過由於其開源社群活躍，已有人為 MetaGPT 添加了自定義 LLM 接口的能力，透過調整配置可以改用不同的模型 API (What is MetaGPT ? | IBM )。\n據 IBM 技術博客報導，MetaGPT 內建支援 OpenAI GPT-3.5 與 GPT-4，同時社群也貢獻了介接其他模型的方案，例如兼容 Anthropic Claude 或其他開源大模型的 API (What is MetaGPT ? | IBM )。\n未來版本計畫支持像 Ollama 這樣的本地 LLM 後端，方便使用本地模型 (What is MetaGPT ? | IBM )。\n然而，目前 MetaGPT 尚未著重工具調用功能；它主要透過代理間的自然語言通信來完成任務拆解和協作，並不內建網絡搜索、程式執行等外部工具接口。\n因此對 OpenAI 的函數調用 (Function Calling) 和 Anthropic MCP 等標準暫無直接支持報導，更側重於利用 LLM 本身的生成能力來產生所需產物。\n總的來說，MetaGPT 的模型兼容性以 OpenAI 平台為主，對替代模型的支持需要自行客製，但架構本身相對獨立於模型實現，具備一定擴充彈性。\n\n# 部署複雜度與資源需求\n\nMetaGPT 作為社群專案，提供了詳細的使用說明和 Docker 鏡像以簡化部署 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n使用者只需準備好 Python 環境（需求 Python 3.10 + 和 Node.js，用於繪製 Mermaid 圖等用途）及 OpenAI API Key，便可在本地運行 MetaGPT。 (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)\n安裝上可以透過 pip 安裝必要套件，或直接使用官方提供的 Docker 容器來避免環境配置問題。\n由於 MetaGPT 大部分計算都在 OpenAI 的雲端完成（GPT-4 推理），本地運行時對硬體要求不高，普通 PC 即可執行其協調任務。\n實測生成一個完整軟體項目可能耗費數美元等級的 API 點數（約使用 0.2 美元生成分析設計，2 美元生成全部代碼及文檔） (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)。\n在運行過程中，MetaGPT 會產生大量文本和文件，需有足夠的磁碟空間存放輸出結果（如 Markdown 設計文檔、代碼檔案、Mermaid 圖等）。\n但除非整合本地模型，否則無需額外 GPU 資源。需要注意的是，MetaGPT 依賴外部服務（OpenAI API），因此部署時要確保網路通暢及 API 服務穩定。\n若團隊在企業環境使用，可能需要將 API 密鑰和生成內容進行安全管理。\n總體而言，MetaGPT 的部署門檻相對友好：\n\n不需要繁瑣的分散式架構或多進程協調，單機即可啟動「AI 軟體公司」。\n資源主要花費在 API 調用成本上，本地計算開銷有限。\n然而，由於其本質上是研究性框架，開發者在生產環境採用時需額外考慮生成內容的驗證和完善，以確保結果符合真實業務需求。\n\n\n\n# AutoGPT\n# 實際應用案例\n\nAutoGPT 是一款由社群開發者 Significant Gravitas 在 GitHub 發布的開源代理項目 (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)。\n它是較早引發廣泛關注的「自主 AI」代理之一，目標是讓 AI 自動連續地執行任務直至達成用戶給定的目標。\nAutoGPT 在推出後被愛好者用於各種實驗性任務：\n\n例如自動建立一個簡單的商業網站、分析市場數據後撰寫投資建議、作為個人助理制定待辦事項等等。\n一些具體案例包括：\n\n「Chef-GPT」自動搜尋食譜並產出購物清單、\n「Crypto-GPT」自主抓取加密貨幣資訊進行分析，\n甚至讓 AutoGPT 充當內容創作工具，從網路上蒐集資訊後撰寫文章草稿。\n\n\nAutoGPT 的官方說明也提供了幾個內建代理實例：\n\n其一會從 Reddit 熱門話題中自動生成短影片腳本，\n另一個能監控 YouTube 頻道的新影片並生成摘要和社群貼文 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.) (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n\n\n這些應用展示了 AutoGPT 將網路搜尋、語音識別、文字生成等多步驟流程串聯起來的能力。\n\n\n值得注意的是，由於 AutoGPT 早期版本的可靠性和事實性有限，多數應用案例仍在試驗階段，社群常分享成功與失敗的經驗以改進代理表現。\n\n# 模型支援與兼容性\n\nAutoGPT 最初專為 OpenAI 的 GPT-4 模型設計，因此對 OpenAI GPT API 有良好支援 (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)。\n預設情況下它使用 GPT-4 作為主要思考和執行代理，並可在需要時切換為成本較低的 GPT-3.5 來執行部分子任務（例如長文檔總結） (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)。\nAutoGPT 通過插件機制擴展功能：\n\n官方實現了多種插件，如網頁瀏覽、網路搜尋、文件讀寫、電子郵件發送等 (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)。\n\n\n這些插件相當於 OpenAI 函數調用的前身方案，代理會在對話中產生特定格式的指令，框架解析後調用對應的函式（例如  _browse_website  或  _send_email ）。\n隨著 OpenAI 函數調用功能推出，新版 AutoGPT 也在逐步適配，以讓模型直接輸出結構化工具調用。\n目前 AutoGPT 主要支持 OpenAI 平臺的模型，對於其他模型如 Claude 或本地 LLM 並無官方直接支持。但社群有一些非官方修改版本，嘗試將 AutoGPT 與本地開源模型（例如 GPT4All、Llama 2）整合，以擺脫對雲端 API 的依賴。\n然而，由於這類開源模型在推理能力和上下文長度上仍有限，實務中 AutoGPT 大多仍依賴 GPT-4 獲得最佳效果。總而言之，AutoGPT 在模型兼容性上相對狹窄但專精：\n\n深度集成並優化了對 OpenAI GPT 系列的使用，具備長上下文對話、函數工具調用、記憶體管理等能力 (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)；要使用非 OpenAI 模型則需額外修改框架核心。\n\n\n\n# 部署複雜度與資源需求\n\nAutoGPT 的部署相對需要一定技術背景，但官方提供了說明文件和 Docker 環境來簡化流程 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n用戶可以選擇本地自托管：\n\n需安裝 Python、Node.js（部分插件可能需要）和相關依賴，將 OpenAI API Key 等配置寫入檔案，然後透過命令行啟動代理 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n官方建議使用 Docker 來一鍵啟動所需環境，以避免本地配置問題 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n\n\nAutoGPT 開發團隊亦推出了雲端托管服務的候補名單，以提供即用型的雲端介面 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n在運行時，AutoGPT 通常以迴圈方式讓 GPT 代理不斷產生行動計劃並執行，因此會持續佔用一個進程。\n其內建內存機制會將對話內容和中間結果存入向量數據庫或本地檔案，以供後續步驟檢索 (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)。\n資源需求方面，AutoGPT 對本地 CPU 和記憶體的需求取決於載入的插件多少；\n\n例如執行瀏覽器插件會啟動無頭瀏覽器，佔用一些記憶體和網絡帶寬。\n但最主要的資源消耗是來自頻繁的 GPT-4 API 調用，以及可能的文件讀寫。\n在沒有本地模型推理的情況下，AutoGPT 不需要 GPU。\n若使用圖像生成等插件（如 Stable Diffusion）並在本地執行，則需要具備相應 GPU。\n\n\n一般而言，一個 AutoGPT 代理執行複雜任務可能持續數分鐘到數小時，在此期間需要穩定的網絡連線和足夠的 API 額度支撐。\n為了監控代理，AutoGPT 帶有前端介面可在 VSCode 中查看代理思路和操作，也提供日誌與分析工具（如  agbenchmark  基準套件）幫助評估代理表現 (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)。\n在生產環境中部署 AutoGPT 仍具挑戰，因其決策不可預測性，需要人員隨時介入校正。\n因此目前 AutoGPT 更多作為探索性項目，被技術社群用來試驗端到端自動化的可能性，其部署主要用於個人或研發而非關鍵業務系統。\n\n# 參考來源\n\nWhat is LangGraph? – IBM Technology Blog (2024) (What is LangGraph? | IBM) (What is LangGraph? | IBM)\nhttps://www.ibm.com/think/topics/langgraph\nlangchain-ai/langgraph (GitHub Repo) – Build resilient language agents as graphs (GitHub - langchain-ai/langgraph: Build resilient language agents as graphs.) (GitHub - langchain-ai/langgraph: Build resilient language agents as graphs.)\nhttps://github.com/langchain-ai/langgraph\nAutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation – Microsoft Research (2024) (AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation - Microsoft Research)\nhttps://www.microsoft.com/en-us/research/publication/autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation-framework/\nMicrosoft's AutoGen: A guide to code-executing agents – Tereza Tizkova, E2B Medium (2023) (Microsoft's AutoGen. A guide to code-executing agents | by Tereza Tizkova | E2B — Cloud runtime for AI agents | Medium) (Microsoft's AutoGen. A guide to code-executing agents | by Tereza Tizkova | E2B — Cloud runtime for AI agents | Medium)\nhttps://medium.com/e-two-b/microsofts-autogen-8aefacbddfa3\nMulti-Agent AutoGen with Functions – Step-by-Step with Code Examples – Dr. Ernesto Lee (2024) (Multi-Agent AutoGen with Functions - Step-by-Step with Code Examples | by Dr. Ernesto Lee | Medium)\nhttps://drlee.io/multi-agent-autogen-with-functions-step-by-step-with-code-examples-2515b3ab2ac6\nEnhanced Support for Non-OpenAI Models (AutoGen 0.2 Blog) – Mark Sze et al., Microsoft (2024) (Enhanced Support for Non-OpenAI Models | AutoGen 0.2)\nhttps://microsoft.github.io/autogen/0.2/blog/2024/06/24/AltModels-Classes/\nGitHub – ag2ai/ag2: The Open-Source AgentOS (AG2, formerly AutoGen) (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ) (GitHub - ag2ai/ag2: AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ)\nhttps://github.com/ag2ai/ag2\nUnlocking the Power of Agentic Workflows at Nexla with AG2 – AG2 Docs User Story (2025) (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2) (Unlocking the Power of Agentic Workflows at Nexla with AG2 - AG2)\nhttps://docs.ag2.ai/docs/user-stories/2025-02-11-NOVA/\nHow to Use Anthropic MCP Tools with Your AutoGen Agents (and any model) – Victor Dibia (2025) (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model)) (How to Use Anthropic MCP Tools with Your AutoGen Agents (and any model))\nhttps://newsletter.victordibia.com/p/how-to-use-mcp-anthropic-mcp-tools\nWhat is MetaGPT? – IBM Technology Blog (2024) (What is MetaGPT ? | IBM ) (What is MetaGPT ? | IBM )\nhttps://www.ibm.com/think/topics/metagpt\nMetaGPT: A Multi-Agent Framework Revolutionizing Software Development – Alexei Korol, Medium (2023) (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium) (MetaGPT: A Multi-Agent Framework Revolutionizing Software Development | by Alexei Korol | Medium)\nhttps://medium.com/@korolalexei/metagpt-a-multi-agent-framework-revolutionizing-software-development-f585fe1aa950\nTop 10 AutoGPT Use Cases to Explore in 2025 – Analytics Vidhya (2024) (Top 10 AutoGPT Use Cases to Explore in 2025 - Analytics Vidhya)\nhttps://www.analyticsvidhya.com/blog/2023/12/autogpt-use-cases/\nSignificant-Gravitas/AutoGPT (GitHub Repo) – AutoGPT: Build, Deploy, and Run AI Agents (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.) (GitHub - Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.)\nhttps://github.com/Significant-Gravitas/AutoGPT\n\n","categories":["NCHC","Agent"],"tags":["NCHC","Agent"]},{"title":"AutoGen 介紹","url":"/AutoGen/","content":"# License\n\nCC-BY-4.0 [1]\nMIT license\n\n# 架構與功能特色\n\n採用多 Agent 對話架構：多個代理人透過交換訊息來合作完成任務​ [2]。\n內建 AssistantAgent（類似 AI 助理）和 UserProxyAgent 等，可組成自動對話或人機混合流程​。\nAgents 可結合 LLM、執行 Python 程式碼或調用工具，實現自動使用工具（例如網路瀏覽、代碼執行）​。\n支援人類監督中斷 / 介入，以及多 Agent 反思、辯論等高階模式​。\n\n# 擴充性與客製化\n\n模組化設計，可透過組合不同內建 Agent 類型構建自訂流程。\n例如增加多個助理 Agent 進行反覆校對或引入自定義工具執行 Agent 等。\n支持多種模型後端（OpenAI、Azure 或本地模型）​，以及擴充套件：如內建 WebSurfer 爬網代理、代碼執行環境等安裝選項​。因此能方便地插入新工具或改寫 Agent 行為邏輯。\n\n# 使用者學習曲線與文件\n\n提供高階封裝，以最小代碼實現複雜多 Agent 應用​。\n上手難度中等，熟悉 Python 開發的使用者可很快根據範例打造出多智能體對話流程。\n官方文件齊全（網站說明、API 參考、FAQ）、範例豐富，涵蓋從基礎到進階主題。並提供 AutoGen Studio 無程式介面降低使用門檻​。\n總體而言對開發者友好，新手需花一些時間理解異步訊息交互模式。\n\n# 作為 SDK/API 封裝供整合（Function Calling、MCP 支援）\n\n以程式庫形式運作，可在應用中建立 Agent 物件並與之通訊，支援函式回呼等模式。\n由於採用訊息對話介面，前端 UI 可以將使用者輸入轉換為 Agent 訊息，再將 Agent 的回覆顯示出來，串接相對直接。\nAutoGen Agent 可產生並執行程式碼等於實現自定義函式執行​；亦能與 LangChain 等集成（官方示例展示了結合 LangGraph、LlamaIndex 等用法​）。\n目前對 MCP 沒有直接實作，但其訊息驅動架構本質上符合事件驅動理念。整體適合封裝為後端服務供 GUI 調用。\n\n# 優缺點總結\n# 優點\n\n提供高階抽象，讓開發者以較少代碼實現多 Agent 對話協作​。\n內建對話代理模式，開箱即可讓多個 LLM 代理人互動，善於處理需要工具使用或代碼執行的任務​。\n擴充性佳，能方便地插入新工具或不同模型​。\n官方文件與支持積極，微軟背景帶來穩定性保障，現已完全開源（Apache 2.0）。\n\n# 缺點\n\n框架相對新穎，生態系統不如 LangChain 豐富，第三方整合資源較少。\n使用異步訊息機制，對不熟悉並發編程的開發者有一定挑戰。\n默認范式偏重聊天形式，對非對話類的任務（如單步批處理任務）可能需要調整。\n另外，轉為社群維護後，未來演進路線需關注社群共識。\n\n# 參考資料\n\n\n\nAutoGen Github ↩︎\n\nmicrosoft.github.io ↩︎\n\n\n\n","categories":["NCHC","Agent"],"tags":["NCHC","Agent"]},{"title":"LangGraph 介紹","url":"/LangGraph/","content":"# License\n\nMIT license [1]\n\n# 架構與功能特色\n\n以圖狀流程控制多 Agent 協作。\n每個 Agent 作為圖中的節點，支援 multi-agent 工作流程與迴圈、分支等複雜控制流程​。\n內建狀態持久化機制提供長期記憶，可在長任務中保留上下文 (checkpoint and snapshot)。[2][3][4]\n並提供 Human-in-the-loop 人工審核功能，提升可靠性​。\n能無縫結合 LangChain 的工具和模型（即插件功能），亦支援串流逐步輸出​。\n\n# 擴充性與客製化\n\n提供低階且可組合的基本元素 (Node, Edges, States, Memory 等)，具高度客製彈性​。\n開發者可自由擴充新的 Agent 節點類型、工具函式、記憶機制等以滿足特殊需求，不受制於固定框架。\n與 LangChain 生態兼容，可直接調用其現有模組（如資料庫、檢索等）。\n適合需要深度定制的應用。\n\n# 使用者學習曲線與文件\n\n由於採用較底層的圖模型，需要開發者理解狀態機 / 資料流概念和 LangChain 元件，學習曲線略陡。[5]\n高度抽象可能對初學者不友好，增加學習曲線。[6]\n複雜性管理：\n\n隨著工作流程的複雜化，管理和調優多個代理之間的交互可能變得更加困難。\n\n\n熟悉後可充分利用其靈活性，對工程實踐有一定要求。\n\n# 作為 SDK/API 封裝供整合（Function Calling、MCP 支援）\n\n作為 Python 套件提供，易於嵌入其他應用後端。\n可透過函式呼叫等方式與 GUI 交互，例如在應用中調用 LangGraph Agent 並取得回應。[7]\n對 OpenAI Function Calling 等新特性支援良好 —— 實務上可將工具函數註冊進 LangGraph，LLM 會自動選擇調用​ [8][9]。\n亦能配合 Anthropic MCP（模型上下文協議）的思想實現事件驅動交互（如將 Agent 狀態作為共享上下文）。[10]\n另外有配套的 LangGraph Studio 可視化介面，方便開發者調試與監控​。\n整體而言，非常適合作為 SDK 平台供其他系統調用。\n\n# 優缺點總結\n# 優點\n\n多 Agent 圖論架構帶來高度靈活性，可構築複雜的流程和長期任務，控制精細。\n內建持久化記憶及人類審核機制，可靠性強​ [11]。\n與 LangChain 生態緊密整合，可直接使用豐富的工具和資源。\n採 MIT 授權且由知名團隊維護，企業採用意願高。\n\n# 缺點\n\n屬低階框架，上手需要較高的工程能力和對 Agent 狀態機的理解\n實現簡單任務時相對繁瑣。\n對初學者不夠友好，開發者可能需要調適參數與架構來達到最佳效果。\n高度模組化也意味著缺少開箱即用的成品模板，需要自行設計 Agent 間的互動。\n\n# 參考資料\n\n\n\nLangGraph Github ↩︎\n\n什麼是 LangGraph 以及如何使用？ ↩︎\n\nLangGraph 状态机：复杂 Agent 任务流程管理实战 ↩︎\n\n用 LangGraph 搭建智能体 —AI Agents in LangGraph（四、持久化和流式输出） ↩︎\n\nlanggraph：正面和負面經驗。先畫狀態圖、條件邊弄清楚、資料流篩什麼留什麼。用數位孿生可先模擬才實作 ↩︎\n\n比較 AutoGen 與 LangGraph 的框架，輕鬆自動排檔與精細手排檔 (除錯有 langsmith)，兩者皆能串流輸出 ↩︎\n\nhttps://blog.langchain.dev/introducing-the-langgraph-functional-api/?utm_source=chatgpt.com ↩︎\n\nlangchain-ai.github.io ↩︎\n\nFunction Calling in Agentic Workflows ↩︎\n\nlanggraph-mcp github ↩︎\n\nlanggchain-ai-langgraph github ↩︎\n\n\n\n","categories":["NCHC","Agent"],"tags":["NCHC","Agent"]},{"title":"MetaGPT 介紹","url":"/MetaGPT/","content":"# License\n\nMIT license [1]\n\n# 架構與功能特色\n\n將整個系統比擬為一個軟體公司的團隊協作。\n內建多個具有專業角色分工的 Agent（如產品經理、架構師、工程師等），按照預先設計的 SOP（標準作業流程）逐步互動。\n單一自然語言需求作為輸入後，Agents 依序產出用戶故事、需求分析、設計、代碼等成果​。[2]\n強調嚴謹的流程管控與專業分工，提高完成複雜任務（特別是軟體開發）的品質。\n相對而言，長期記憶或外部插件工具支援不是重點（需要自行擴充）。\n\n# 擴充性與客製化\n\n提供較固定的模板（軟體開發 SOP）。\n使用者可透過調整設定檔 YAML 來開關某些步驟或角色，但框架本身針對軟體開發進行了優化和約束。\n缺少通用的插件機制來快速增加新工具類型。\n要大幅改變流程（例如應用於非開發任務）需要修改源碼中流程定義，客製化門檻較高。\n適合在其設計範疇內擴充細節，不適合偏離軟體開發範式的大改造。\n\n# 使用者學習曲線與文件\n\n針對軟體開發場景提供了開箱即用的體驗：\n\n只需輸入一行需求即可跑出完整結果，初學者也能很快看到成果。\n\n\n然而要調整或深入干預流程需要理解其多 Agent SOP，學習成本較高。\n簡單跑範例很快，但要自訂流程需要相當的學習投入。\n\n# 作為 SDK/API 封裝供整合（Function Calling、MCP 支援）\n\n主要以命令列工具形式運行，一次輸入需求後批量輸出結果，缺乏持續交互的 API 設計。\n沒有針對 function calling 或 MCP 的專門支援，因為其流程相對封閉固定。\n若要整合進其他系統，需自行改造其執行流程或呼叫其內部函式，開發成本較高。\n更適合作為一個獨立應用離線使用，而非嵌入式的服務元件。\n\n# 優缺點總結\n# 優點\n\n創新的多人角色協作理念，將人類軟體開發流程知識融入 Agent SOP，適合複雜專案型任務。\n對於軟體開發自動化，有明確的結構和輸出格式，可一步產出完整文檔和代碼骨架​。\n社群人氣高，說明文檔有多語言版本，非英文使用者也易於學習。\nMIT 授權開源，長期發展潛力大。\n\n# 缺點\n\n用途侷限在軟體研發領域，內建的 agent 角色和流程不太適用其他任務場景。\n框架封裝程度高，靈活度相對不足，開發者難以偏離預設流程進行定制。[3]\n需要同時理解多個角色的交互，本身邏輯複雜，調試困難度較大。\n缺少插件 / 工具擴展支持，無法輕易整合額外能力（如網路檢索或圖像識別）。\n\n# 參考資料\n\n\n\nMetaGPT Github ↩︎\n\nMetaGPT: 多智能体框架 ↩︎\n\nMetaGPT 与 ChatDev ↩︎\n\n\n\n","categories":["NCHC","Agent"],"tags":["NCHC","Agent"]}]